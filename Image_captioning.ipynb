{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import cv2\n",
    "import json\n",
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Flickr8k/Flickr_TextData/Flickr8k.token.txt') as f:\n",
    "    data=f.read()\n",
    "data=data.split('\\n')[:-1] #last entry is empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1000268201_693b08cb0e.jpg#0\\tA child in a pink dress is climbing up a set of stairs in an entry way .'"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning\n",
    "stemming ,lemmatising , stopword removal techniques have not been performed while cleaning the captions so as to teach model write captions with correct english otherwise - a caption like 'A child in a pink dress is climbing up a set of stairs in an entry way' model will predict caption of form 'child pink dress climb set of stairs entry way' which doesn't make sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(sentence):\n",
    "    sentence = sentence.lower()\n",
    "    sentence = re.sub(\"[^a-z]+\",\" \",sentence)\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "captions={}\n",
    "for i in range(len(data)):\n",
    "    img_name,img_caption=data[i].split('\\t')\n",
    "    img_name=img_name.split('.jpg')[0]\n",
    "    img_caption=clean_text(img_caption)\n",
    "    if captions.get(img_name) is None:\n",
    "        captions[img_name] = []\n",
    "    captions[img_name].append(img_caption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(captions)\n",
    "with open(\"cleaned_caption_description.json\", \"w\") as file:\n",
    "    json.dump(captions, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"cleaned_caption_description.json\", \"r\") as file:\n",
    "    captions=json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### creating Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total words= 437466\n",
      "no of unique words= 8441\n"
     ]
    }
   ],
   "source": [
    "total_words=[]\n",
    "for img_name in captions.keys():\n",
    "    [total_words.append(i) for sent in captions[img_name] for i in sent.split()]\n",
    "print('total words= {}'.format(len(total_words)))\n",
    "count=np.array(np.unique(total_words,return_counts=True))\n",
    "count=[(count[0][i],count[1][i])for i in range(count.shape[1])]\n",
    "print('no of unique words= {}'.format(len(count))) #no of unique words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of unique words= 1850\n"
     ]
    }
   ],
   "source": [
    "#reducing size of vocab by removing words with frequency less than 10\n",
    "size=10\n",
    "vocab=[w[0] for w in count if int(w[1])>size]\n",
    "print('no of unique words= {}'.format(len(vocab)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=None\n",
    "test=[]\n",
    "with open('../Flickr8k/Flickr_TextData/Flickr_8k.trainImages.txt') as f:\n",
    "    train=f.readlines()\n",
    "with open('../Flickr8k/Flickr_TextData/Flickr_8k.testImages.txt') as f:\n",
    "    test=f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=[c.split('.jpg')[0] for c in train]\n",
    "test=[c.split('.jpg')[0] for c in test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2513260012_03d33305cf', '2903617548_d3e38d7f88', '3338291921_fe7ae0c8f8', '488416045_1c6d903fe0', '2644326817_8f45080b87']\n"
     ]
    }
   ],
   "source": [
    "print(train[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<start\\> (start-of-sequence) and <end\\> (end-of-sequence) characters are added to every caption to help our model determine when to start and - more importantly - end sequences.\n",
    "Because while generating text(captions) model should know when it has to end otherwise it will keep predicting words and add them to the captions.  That's why we teach our model to decide the length of a caption on that by itself. when model will predict <end\\> as next word for the caption, model should stop predicting more words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare train descriptions\n",
    "train_descriptions={}\n",
    "for t in train:\n",
    "    train_descriptions[t]=[]\n",
    "    for sent in captions[t]:\n",
    "        new_caption='<start>'+sent+'<end>'\n",
    "        train_descriptions[t].append(new_caption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_descriptions.json','w') as file:\n",
    "    json.dump(train_descriptions,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_descriptions.json','r') as file:\n",
    "    train_descriptions=json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
